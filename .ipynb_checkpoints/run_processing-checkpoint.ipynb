{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline\n",
    "from scipy.stats import zscore\n",
    "import imp\n",
    "# modules\n",
    "import decoders, utils, tuning, learning, mainfigs, suppfigs\n",
    "\n",
    "### WHERE YOU DOWNLOADED THE FIGSHARE\n",
    "dataroot = 'Z:/releases/stringer-et-al-2019a/fs125'\n",
    "\n",
    "# file list\n",
    "db = np.load(os.path.join(dataroot, 'database.npy'), allow_pickle=True)\n",
    "fs = []\n",
    "for di in db:\n",
    "    mname = di['mouse_name']\n",
    "    datexp = di['date']\n",
    "    blk = di['block']\n",
    "    stype = di['expt']\n",
    "    \n",
    "    fname = '%s_%s_%s_%s.npy'%(stype, mname, datexp, blk)\n",
    "    fs.append(os.path.join(dataroot, fname))\n",
    "\n",
    "### WHERE YOU WANT TO SAVE THE OUTPUTS OF THE ANALYSIS SCRIPTS AND THE FIGURES (if save_figure=True)\n",
    "saveroot = 'D:\\DATA\\stringer-etal2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> linear <<<<<<<<<<<<<<\n",
      "gratings_static_GT1_2019_04_17_1.npy 1.0099088971944066\n",
      "gratings_static_GT2_2019_04_17_1.npy 0.9873921626617418\n",
      "gratings_static_GT3_2019_04_17_1.npy 0.9305697620593152\n",
      "gratings_static_TX38_2019_05_02_2.npy 1.1909904633718167\n",
      "gratings_static_TX39_2019_05_02_1.npy 1.0511329699289431\n",
      "gratings_static_TX40_2019_05_02_1.npy 1.0021785573103996\n",
      "gratings_local_GT1_2019_04_27_2.npy 1.281445952689518\n",
      "gratings_local_GT2_2019_04_23_2.npy 1.2463278704526575\n",
      "gratings_local_GT3_2019_04_24_2.npy 1.6420898787437388\n",
      "minnie_GT1_2019_04_29_2.npy 0.8850283653518349\n",
      "minnie_GT2_2019_04_25_1.npy 0.9126825318211667\n",
      "minnie_GT3_2019_04_27_3.npy 0.9981296260809154\n",
      "minnie_TX38_2019_05_07_4.npy 1.001288524420484\n",
      "minnie_TX39_2019_05_08_2.npy 1.6404117930934812\n",
      "minnie_TX40_2019_05_06_2.npy 1.090744501964375\n",
      "gratings_short_GT1_2019_04_28_5.npy 1.5025934075284986\n",
      "gratings_short_GT2_2019_04_29_1.npy 1.6365600478575881\n",
      "gratings_short_GT3_2019_04_25_3.npy 1.686156801313896\n",
      "gratings_drifting_GT1_2019_04_12_1.npy 1.0266574916466564\n",
      "gratings_drifting_GT2_2019_04_05_1.npy 0.82789308452127\n",
      "gratings_drifting_GT3_2019_04_05_1.npy 1.1156419030992883\n",
      "gratings_low_contrast_GT1_2019_04_09_1.npy 1.7255270998949295\n",
      "gratings_low_contrast_GT2_2019_04_12_2.npy 1.6399668682755688\n",
      "gratings_low_contrast_GT3_2019_04_12_1.npy 1.95462992738709\n",
      "gratings_noisy_GT1_2019_04_08_1.npy 1.2677716009883448\n",
      "gratings_noisy_GT2_2019_04_08_1.npy 1.7983259930244957\n",
      "gratings_noisy_GT3_2019_04_08_1.npy 1.6105425131104212\n",
      "asymp for:  gratings_static_GT1_2019_04_17_1.npy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-da44dad079bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m### ASYMPTOTIC ANALYSIS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mccE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnstim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masymptotics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mislinear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     np.save(os.path.join(saveroot,'%s_decoder_asymp.npy'%dstr[dtype]), \n\u001b[0;32m     25\u001b[0m                 {'E': E, 'ccE': ccE, 'nsplit': nsplit, 'npop': npop, 'nstim': nstim, 'E2': E2})\n",
      "\u001b[1;32mD:\\Github\\stringer-et-al-2019\\decoders.py\u001b[0m in \u001b[0;36masymptotics\u001b[1;34m(fs, linear, npc)\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0miSS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnstim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvonmises_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mistim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miSS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindependent_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mistim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miSS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~ DATA ANALYSIS ~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "\n",
    "################### DECODING ANGLES 0-360 #######################\n",
    "dstr = ['independent', 'linear']\n",
    "for dtype in range(1,2):\n",
    "    print('>>>>>>>>>> %s <<<<<<<<<<<<<<'%dstr[dtype])\n",
    "    if dtype==0:\n",
    "        islinear=False\n",
    "    else:\n",
    "        islinear=True\n",
    "        \n",
    "    ### DECODER\n",
    "    E, errors, stims, SNR, theta_pref = decoders.run_decoder(fs[:27], linear=islinear)\n",
    "    if dtype==1:\n",
    "        np.save(os.path.join(saveroot,'%s_decoder_all_stims.npy'%dstr[dtype]), \n",
    "                {'E': E, 'errors': errors, 'stims': stims})\n",
    "    else:\n",
    "        np.save(os.path.join(saveroot,'%s_decoder_all_stims.npy'%dstr[dtype]), \n",
    "                {'E': E, 'errors': errors, 'stims': stims, 'SNR': SNR, 'theta_pref': theta_pref})\n",
    "\n",
    "    ### ASYMPTOTIC ANALYSIS\n",
    "    E, ccE, nsplit, npop, nstim, E2 = decoders.asymptotics(fs[:6], linear=islinear)\n",
    "    np.save(os.path.join(saveroot,'%s_decoder_asymp.npy'%dstr[dtype]), \n",
    "                {'E': E, 'ccE': ccE, 'nsplit': nsplit, 'npop': npop, 'nstim': nstim, 'E2': E2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### decoding without subtracting spont\n",
    "E, errors, stims, SNR, theta_pref = decoders.run_decoder(fs[:27], linear=islinear, npc=0)\n",
    "np.save(os.path.join(saveroot,'%s_decoder_with_spont.npy'%dstr[dtype]), \n",
    "                {'E': E, 'errors': errors, 'stims': stims})\n",
    "\n",
    "### linear decoding from PC's\n",
    "nPC = 2**np.arange(2,13,1)\n",
    "errors, apreds, atrues = decoders.pc_decoding(fs[:6], nPC)\n",
    "np.save(os.path.join(saveroot, 'pcdecode.npy'), \n",
    "        {'errors': errors, 'apreds': apreds, 'atrues': atrues, 'nPC': nPC})\n",
    " \n",
    "\n",
    "#################### SINGLE NEURON STATS ########################\n",
    "\n",
    "# load a dataset for stim distances\n",
    "dat = np.load(fs[0], allow_pickle=True).item()\n",
    "sresp, istim, itrain, itest = utils.compile_resp(dat, npc=npc)\n",
    "\n",
    "### STIMULUS DISTANCES\n",
    "cc, dtheta_aligned, cbinned, embedding = tuning.population_distances(sresp, istim)\n",
    "np.save(os.path.join(saveroot,'popdist.npy'), \n",
    "        {'cc':cc, 'dtheta_aligned': dtheta_aligned, 'cbinned':cbinned,'embedding':embedding, 'istim': istim})\n",
    "\n",
    "###### population tuning curves\n",
    "d = np.load(os.path.join(saveroot, 'independent_decoder_all_stims.npy'), allow_pickle=True).item()\n",
    "angle_pref = d['theta_pref']\n",
    "### static gratings population tuning curves\n",
    "avg_tuning, tbins = tuning.population_tuning(fs[:6], angle_pref[:6], saveroot)\n",
    "np.save(os.path.join(saveroot,'avgneur_static.npy'), \n",
    "        {'avg_tuning': avg_tuning, 'thetas': angle_pref[:6], 'tbins': tbins})\n",
    "\n",
    "### drifting gratings population tuning curves\n",
    "avg_tuning, tbins = tuning.population_tuning(fs[18:21], angle_pref[18:21], saveroot)\n",
    "np.save(os.path.join(saveroot,'avgneur_drifting.npy'), \n",
    "        {'avg_tuning': avg_tuning, 'thetas': angle_pref[18:21], 'tbins': tbins})\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "################ DISCRIMINATION TASK #######################\n",
    "print('DISCRIMINATION')\n",
    "\n",
    "### linear discriminator (all datasets except biased)\n",
    "P,d75,drange = decoders.run_discrimination(fs[:27], decoder='linear')\n",
    "np.save(os.path.join(saveroot, 'linear_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### linear discriminator on biased datasets (43-47 degree stimuli shown only)\n",
    "npop,nstim,Pstim,Pneur,drange = decoders.dense_discrimination(fs[27:])\n",
    "np.save(os.path.join(saveroot, 'dense_discrimination.npy'), \n",
    "        {'npop': npop, 'nstim': nstim, 'Pneur': Pneur, 'Pstim': Pstim, 'drange': drange})\n",
    "\n",
    "###  discrimination in passive versus running trials\n",
    "all_running = np.load(os.path.join(dataroot, 'all_running.npy'))\n",
    "P,d75,drange = decoders.runspeed_discrimination(fs[:6], all_running[:6])\n",
    "np.save(os.path.join(saveroot, 'runspeed_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### depth discrimination (split into layers 2/3 and layer 4)\n",
    "all_depths = np.load(os.path.join(dataroot, 'all_depths.npy'))\n",
    "P,d75,drange = decoders.layer_discrimination(fs[:6], all_depths[:6])\n",
    "np.save(os.path.join(saveroot, 'layer_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### chron discrimination (split train/test in time)\n",
    "P,d75,drange = decoders.chron_discrimination(fs[:6], all_depths[:6])\n",
    "np.save(os.path.join(saveroot, 'chron_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### neural network discriminator\n",
    "P,d75,drange = decoders.run_discrimination(fs[:6], decoder='deep_net')\n",
    "np.save(os.path.join(saveroot, 'nn_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### random forest discriminator\n",
    "P,d75,drange = decoders.run_discrimination(fs[:6], decoder='random_forest')\n",
    "np.save(os.path.join(saveroot, 'rf_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "#~~~~~~~~~~~~~~~ PERCEPTRONS ~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "### PERCEPTRONS\n",
    "# train on easy task\n",
    "nstim32, perf32 = learning.train_perceptrons(fs[:6], task_type='easy')\n",
    "# train on hard task\n",
    "nstim, perf = learning.train_perceptrons(fs[27:], task_type='hard')\n",
    "np.save(os.path.join(saveroot, 'strong_learn.npy'), \n",
    "         {'nstim32': nstim32, 'perf32': perf32, 'perf': perf, 'nstim': nstim})\n",
    "\n",
    "\n",
    "### WEAK LEARNERS\n",
    "# train on easy task\n",
    "P, drange, ccN = learning.train_weak_learners(fs[:6])\n",
    "np.save(os.path.join(saveroot, 'weak_learn.npy'), {'P': P, 'drange': drange, 'ccN': ccN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.close_figures = False\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "\n",
    "imp.reload(mainfigs)\n",
    "imp.reload(suppfigs)\n",
    "\n",
    "#### MAIN FIGURES\n",
    "\n",
    "#### SUPPLEMENTARY FIGURES\n",
    "# if you want to save the figures, add an optional input save_figure=True\n",
    "\n",
    "f = mainfigs.fig1(dataroot, saveroot)\n",
    "\n",
    "f = mainfigs.fig2(dataroot, saveroot)\n",
    "\n",
    "f = mainfigs.fig3(dataroot,saveroot)\n",
    "\n",
    "f = mainfigs.fig4(dataroot, saveroot)\n",
    "\n",
    "f = suppfigs.population_curves(saveroot)\n",
    "\n",
    "f = suppfigs.stim_distances(saveroot)\n",
    "\n",
    "f = suppfigs.pc_errors(saveroot)\n",
    "\n",
    "f = suppfigs.linear_decoders(dataroot, saveroot)\n",
    "\n",
    "f = suppfigs.asymptotics(saveroot)\n",
    "\n",
    "f = suppfigs.spont_sub(saveroot)\n",
    "\n",
    "f = suppfigs.discr_chron(saveroot)\n",
    "\n",
    "f = suppfigs.discr_layers(saveroot)\n",
    "\n",
    "f = suppfigs.discr_nn_rf(saveroot)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
